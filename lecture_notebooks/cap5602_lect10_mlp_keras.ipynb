{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63GSckRspoZJ"
   },
   "source": [
    "# Multi-layer perceptrons with Keras (CAP5602 Lecture 10)\n",
    "\n",
    "In this demo, we will train and test a multi-layer perceptron model on the MNIST handwritten digits dataset using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aieNmVBO2II"
   },
   "source": [
    "## 1. Load dataset\n",
    "\n",
    "Like sklearn, Keras also provides an API to download and load the MNIST dataset. The following code snippet will download the data, load it into memory, and convert pixel values to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N8WM9P0lLYas"
   },
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 00:58:57.954633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqG4Ms29F9z_"
   },
   "source": [
    "## 2. Show a few training examples and its label"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WffFB6scGCh0"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_id = 5\n",
    "image = X_train[img_id]\n",
    "label = Y_train[img_id]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(label)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAc2klEQVR4nO3df3DU9b3v8dcSwgKaLIaQXxIw4A9afqQthTRVESUXSOdYUM69+GsGvA6ONHgK+GvSo+CPzkmLM9TqRbnnTAu1V9DaI3DknHJGgwnXGmhBORzaGgmmAgcSKi27IZgQks/9g+vWlQT8LLt5J+H5mPnOkN3vO9+PX3d8+mU33wScc04AAHSzftYLAABcnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAw0d96AZ/X0dGhw4cPKy0tTYFAwHo5AABPzjk1NTUpLy9P/fp1fZ3T4wJ0+PBh5efnWy8DAHCBDh48qOHDh3f5fI8LUFpamiTpOn1L/ZVqvBoAgK/TatPb+rfof8+7krQArVq1Sk8//bQaGhpUWFio5557TpMnTz7v3Kd/7dZfqeofIEAA0Ov8/zuMnu9tlKR8COGVV17R0qVLtXz5cr377rsqLCzUjBkzdPTo0WQcDgDQCyUlQCtXrtSCBQt0991368tf/rJWr16twYMH66c//WkyDgcA6IUSHqBTp05p165dKikp+etB+vVTSUmJampqztq/tbVVkUgkZgMA9H0JD9DHH3+s9vZ2ZWdnxzyenZ2thoaGs/avqKhQKBSKbnwCDgAuDuY/iFpeXq5wOBzdDh48aL0kAEA3SPin4DIzM5WSkqLGxsaYxxsbG5WTk3PW/sFgUMFgMNHLAAD0cAm/AhowYIAmTpyoysrK6GMdHR2qrKxUcXFxog8HAOilkvJzQEuXLtW8efP09a9/XZMnT9Yzzzyj5uZm3X333ck4HACgF0pKgObOnas//elPWrZsmRoaGvSVr3xFW7ZsOeuDCQCAi1fAOeesF/FZkUhEoVBIUzWLOyEAQC902rWpSpsUDoeVnp7e5X7mn4IDAFycCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP9rRcA4ItJGZrhPRMIpcd1rANz8rxnWjKd98yVT/yH90zHyZPeM+iZuAICAJggQAAAEwkP0OOPP65AIBCzjRkzJtGHAQD0ckl5D2js2LF68803/3qQ/rzVBACIlZQy9O/fXzk5Ocn41gCAPiIp7wHt27dPeXl5GjVqlO68804dOHCgy31bW1sViURiNgBA35fwABUVFWnt2rXasmWLXnjhBdXX1+v6669XU1NTp/tXVFQoFApFt/z8/EQvCQDQAwWcc/4f3vdw/PhxjRw5UitXrtQ999xz1vOtra1qbW2Nfh2JRJSfn6+pmqX+gdRkLg3oVfg5oDP4OaCe77RrU5U2KRwOKz2969dg0j8dMGTIEF199dWqq6vr9PlgMKhgMJjsZQAAepik/xzQiRMntH//fuXm5ib7UACAXiThAXrwwQdVXV2tP/7xj3rnnXd0yy23KCUlRbfffnuiDwUA6MUS/ldwhw4d0u23365jx45p2LBhuu6667R9+3YNGzYs0YcCAPRiCQ/Qyy+/nOhvCfRo/cb53+ljX/kg75n/Of4d75kHhv6790x3+lL2fd4zV83flYSVwAL3ggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATCT9F9IBFgKTxsc1V7ckxXum6rr/5T0zLMX/lzD2i+P/F//15GXeM5L0YWuW90zZZbXeMz+f8k/eM09Nmuc94377n94zSD6ugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCu2GjW6UMG+Y988GPL/eeef2bz3vPSNKo1NQ4pvzvbB2PNZF875mNc66L61gdQf/zULbZ/27YXw+2e898kj3Ie2ag9wS6A1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaKbvVfd13lPfO7G34cx5Hiualo9/k/8dxYdPY3vWfaaz/wnpGkwFfHxjUH+OAKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1I0a0u//YfrZdwTr88keM9s/KDad4z2Q8775n22n3eM/H6y/j0bjsWLl5cAQEATBAgAIAJ7wBt27ZNN998s/Ly8hQIBLRx48aY551zWrZsmXJzczVo0CCVlJRo377u+6sDAEDv4B2g5uZmFRYWatWqVZ0+v2LFCj377LNavXq1duzYoUsuuUQzZsxQS0vLBS8WANB3eH8IobS0VKWlpZ0+55zTM888o0cffVSzZs2SJL344ovKzs7Wxo0bddttt13YagEAfUZC3wOqr69XQ0ODSkpKoo+FQiEVFRWppqam05nW1lZFIpGYDQDQ9yU0QA0NDZKk7OzsmMezs7Ojz31eRUWFQqFQdMvPz0/kkgAAPZT5p+DKy8sVDoej28GDB62XBADoBgkNUE7OmR/ia2xsjHm8sbEx+tznBYNBpaenx2wAgL4voQEqKChQTk6OKisro49FIhHt2LFDxcXFiTwUAKCX8/4U3IkTJ1RXVxf9ur6+Xrt371ZGRoZGjBihxYsX6/vf/76uuuoqFRQU6LHHHlNeXp5mz56dyHUDAHo57wDt3LlTN954Y/TrpUuXSpLmzZuntWvX6uGHH1Zzc7PuvfdeHT9+XNddd522bNmigQMHJm7VAIBezztAU6dOlXNd30gxEAjoySef1JNPPnlBC0MftSDoPfLlsvu9Z/LfaPeekaRLftf5pzXPJfOjD7xn4ltd9zmZHbBeAi4C5p+CAwBcnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC+27YwIVor6v3nrlyif9MvE5325F6trZJTdZLwEWAKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwUu0IFl3/SeOT3Y+R8o4D+iOA4jSbdeVRPfoKdFh6Z6zwza8q73TJynAUnGFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkaLHS0lP955pmXxVXMdKLW/0ntkz5rm4juUrNZDiPdPm2pOwks699clg75lD947wnnGn/+A9g56JKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I0XcAsGg98ypG8Z7zyx5/ufeMzcOqvSekaTG9lbvmbc+ucx7ZtkHs7xn1o9d6z2T19//31G8BvZr85758H8M8Z4ZVTvQe6ajpcV7BsnHFRAAwAQBAgCY8A7Qtm3bdPPNNysvL0+BQEAbN26MeX7+/PkKBAIx28yZMxO1XgBAH+EdoObmZhUWFmrVqlVd7jNz5kwdOXIkuq1fv/6CFgkA6Hu8P4RQWlqq0tLSc+4TDAaVk5MT96IAAH1fUt4DqqqqUlZWlq655hotXLhQx44d63Lf1tZWRSKRmA0A0PclPEAzZ87Uiy++qMrKSv3whz9UdXW1SktL1d7e+e+mr6ioUCgUim75+fmJXhIAoAdK+M8B3XbbbdE/jx8/XhMmTNDo0aNVVVWladOmnbV/eXm5li5dGv06EokQIQC4CCT9Y9ijRo1SZmam6urqOn0+GAwqPT09ZgMA9H1JD9ChQ4d07Ngx5ebmJvtQAIBexPuv4E6cOBFzNVNfX6/du3crIyNDGRkZeuKJJzRnzhzl5ORo//79evjhh3XllVdqxowZCV04AKB38w7Qzp07deONN0a//vT9m3nz5umFF17Qnj179LOf/UzHjx9XXl6epk+frqeeekrBOO4bBgDouwLOOWe9iM+KRCIKhUKaqlnqH0i1Xs5Fod9A/5s7StKxuV/1nvm///BsXMfyNXb9/XHNDX+r809rnkvwX3/rPdM/1//n5K7993rvmQeG7vWe6emKn/o775nsF/8jrmN1nDwZ19zF7rRrU5U2KRwOn/N9fe4FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMJ/5XcsBWI49devL9yQlzHen9W99zZelbtbO+Zq5/+MK5jtTce9Z7pnz/ce6bwXw54zzw09PfeM+GOU94zklT0zw94z+SO8T93leNf8Z6pecz/dTf39r/xnpGkj58d7z0z8FhbXMfylVL1brccJ5m4AgIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHAz0h4s0N//X0/tM4XeM+9/e5X3jCQdOt3qPfPt//2w98wVP93vPXM6jpuKSlJbyUTvmXE/fM97ZnnWLu+ZNZGR3jM///ubvWck6crXtnvPpGQO9Z6Z+t/u955pnhv2ntnw1X/ynpGk4c/639w3Hpub/c/dP149Kgkr6V5cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZaQ928KHJ3jPvf/vH3jOH47ipqCT99x885D1zxcYPvWf+fFOB94y7K817RpJ+Oc7//A1L8b9h5diX/W/CefU/fuw9M7h2h/dMvNo/PuY9k74+nhnvEf3td/xvgitJ2X/7UVxz3h4YEsfQ7xK9im7HFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLgnHPWi/isSCSiUCikqZql/oFU6+WY+vsPd3vPFAXbvGf+3B7fzUhX/6XIe+byAX/xnpmX3k03hIzT2HV/5z1zZflvvWfc6dPeM4CF065NVdqkcDis9PT0LvfjCggAYIIAAQBMeAWooqJCkyZNUlpamrKysjR79mzV1tbG7NPS0qKysjINHTpUl156qebMmaPGxsaELhoA0Pt5Bai6ulplZWXavn273njjDbW1tWn69Olqbm6O7rNkyRK9/vrrevXVV1VdXa3Dhw/r1ltvTfjCAQC9m9dvRN2yZUvM12vXrlVWVpZ27dqlKVOmKBwO6yc/+YnWrVunm266SZK0Zs0afelLX9L27dv1jW98I3ErBwD0ahf0HlA4HJYkZWRkSJJ27dqltrY2lZSURPcZM2aMRowYoZqamk6/R2trqyKRSMwGAOj74g5QR0eHFi9erGuvvVbjxo2TJDU0NGjAgAEaMmRIzL7Z2dlqaGjo9PtUVFQoFApFt/z8/HiXBADoReIOUFlZmfbu3auXX375ghZQXl6ucDgc3Q4ePHhB3w8A0Dt4vQf0qUWLFmnz5s3atm2bhg8fHn08JydHp06d0vHjx2OughobG5WTk9Pp9woGgwoGg/EsAwDQi3ldATnntGjRIm3YsEFbt25VQUFBzPMTJ05UamqqKisro4/V1tbqwIEDKi4uTsyKAQB9gtcVUFlZmdatW6dNmzYpLS0t+r5OKBTSoEGDFAqFdM8992jp0qXKyMhQenq67r//fhUXF/MJOABADK8AvfDCC5KkqVOnxjy+Zs0azZ8/X5L0ox/9SP369dOcOXPU2tqqGTNm6Pnnn0/IYgEAfQc3I+3Brt/T4j3z0ND/TMJKbP3N+/4/yHygZvj5d+rEqF+GvWfc7+r8Z9pOec8AvQU3IwUA9GgECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEddvREX3eOfGPO+Zojtv8p4JF8Z3Z+b+f/K/W/nVq//L/zgNR71nrmiJ71e7d8Q1BSAeXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GWkP1n7sz94z2c++4z/jPRG/0914LAA9G1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAmvAFVUVGjSpElKS0tTVlaWZs+erdra2ph9pk6dqkAgELPdd999CV00AKD38wpQdXW1ysrKtH37dr3xxhtqa2vT9OnT1dzcHLPfggULdOTIkei2YsWKhC4aAND79ffZecuWLTFfr127VllZWdq1a5emTJkSfXzw4MHKyclJzAoBAH3SBb0HFA6HJUkZGRkxj7/00kvKzMzUuHHjVF5erpMnT3b5PVpbWxWJRGI2AEDf53UF9FkdHR1avHixrr32Wo0bNy76+B133KGRI0cqLy9Pe/bs0SOPPKLa2lq99tprnX6fiooKPfHEE/EuAwDQSwWccy6ewYULF+pXv/qV3n77bQ0fPrzL/bZu3app06aprq5Oo0ePPuv51tZWtba2Rr+ORCLKz8/XVM1S/0BqPEsDABg67dpUpU0Kh8NKT0/vcr+4roAWLVqkzZs3a9u2beeMjyQVFRVJUpcBCgaDCgaD8SwDANCLeQXIOaf7779fGzZsUFVVlQoKCs47s3v3bklSbm5uXAsEAPRNXgEqKyvTunXrtGnTJqWlpamhoUGSFAqFNGjQIO3fv1/r1q3Tt771LQ0dOlR79uzRkiVLNGXKFE2YMCEp/wAAgN7J6z2gQCDQ6eNr1qzR/PnzdfDgQd11113au3evmpublZ+fr1tuuUWPPvroOf8e8LMikYhCoRDvAQFAL5WU94DO16r8/HxVV1f7fEsAwEWKe8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz0t17A5znnJEmn1SY548UAALydVpukv/73vCs9LkBNTU2SpLf1b8YrAQBciKamJoVCoS6fD7jzJaqbdXR06PDhw0pLS1MgEIh5LhKJKD8/XwcPHlR6errRCu1xHs7gPJzBeTiD83BGTzgPzjk1NTUpLy9P/fp1/U5Pj7sC6tevn4YPH37OfdLT0y/qF9inOA9ncB7O4DycwXk4w/o8nOvK51N8CAEAYIIAAQBM9KoABYNBLV++XMFg0HoppjgPZ3AezuA8nMF5OKM3nYce9yEEAMDFoVddAQEA+g4CBAAwQYAAACYIEADARK8J0KpVq3TFFVdo4MCBKioq0m9+8xvrJXW7xx9/XIFAIGYbM2aM9bKSbtu2bbr55puVl5enQCCgjRs3xjzvnNOyZcuUm5urQYMGqaSkRPv27bNZbBKd7zzMnz//rNfHzJkzbRabJBUVFZo0aZLS0tKUlZWl2bNnq7a2NmaflpYWlZWVaejQobr00ks1Z84cNTY2Gq04Ob7IeZg6depZr4f77rvPaMWd6xUBeuWVV7R06VItX75c7777rgoLCzVjxgwdPXrUemndbuzYsTpy5Eh0e/vtt62XlHTNzc0qLCzUqlWrOn1+xYoVevbZZ7V69Wrt2LFDl1xyiWbMmKGWlpZuXmlyne88SNLMmTNjXh/r16/vxhUmX3V1tcrKyrR9+3a98cYbamtr0/Tp09Xc3BzdZ8mSJXr99df16quvqrq6WocPH9att95quOrE+yLnQZIWLFgQ83pYsWKF0Yq74HqByZMnu7KysujX7e3tLi8vz1VUVBiuqvstX77cFRYWWi/DlCS3YcOG6NcdHR0uJyfHPf3009HHjh8/7oLBoFu/fr3BCrvH58+Dc87NmzfPzZo1y2Q9Vo4ePeokuerqaufcmX/3qamp7tVXX43u84c//MFJcjU1NVbLTLrPnwfnnLvhhhvcd7/7XbtFfQE9/gro1KlT2rVrl0pKSqKP9evXTyUlJaqpqTFcmY19+/YpLy9Po0aN0p133qkDBw5YL8lUfX29GhoaYl4foVBIRUVFF+Xro6qqSllZWbrmmmu0cOFCHTt2zHpJSRUOhyVJGRkZkqRdu3apra0t5vUwZswYjRgxok+/Hj5/Hj710ksvKTMzU+PGjVN5eblOnjxpsbwu9bibkX7exx9/rPb2dmVnZ8c8np2drffff99oVTaKioq0du1aXXPNNTpy5IieeOIJXX/99dq7d6/S0tKsl2eioaFBkjp9fXz63MVi5syZuvXWW1VQUKD9+/fre9/7nkpLS1VTU6OUlBTr5SVcR0eHFi9erGuvvVbjxo2TdOb1MGDAAA0ZMiRm3778eujsPEjSHXfcoZEjRyovL0979uzRI488otraWr322muGq43V4wOEvyotLY3+ecKECSoqKtLIkSP1i1/8Qvfcc4/hytAT3HbbbdE/jx8/XhMmTNDo0aNVVVWladOmGa4sOcrKyrR3796L4n3Qc+nqPNx7773RP48fP165ubmaNm2a9u/fr9GjR3f3MjvV4/8KLjMzUykpKWd9iqWxsVE5OTlGq+oZhgwZoquvvlp1dXXWSzHz6WuA18fZRo0apczMzD75+li0aJE2b96st956K+bXt+Tk5OjUqVM6fvx4zP599fXQ1XnoTFFRkST1qNdDjw/QgAEDNHHiRFVWVkYf6+joUGVlpYqLiw1XZu/EiRPav3+/cnNzrZdipqCgQDk5OTGvj0gkoh07dlz0r49Dhw7p2LFjfer14ZzTokWLtGHDBm3dulUFBQUxz0+cOFGpqakxr4fa2lodOHCgT70eznceOrN7925J6lmvB+tPQXwRL7/8sgsGg27t2rXu97//vbv33nvdkCFDXENDg/XSutUDDzzgqqqqXH19vfv1r3/tSkpKXGZmpjt69Kj10pKqqanJvffee+69995zktzKlSvde++95z766CPnnHM/+MEP3JAhQ9ymTZvcnj173KxZs1xBQYH75JNPjFeeWOc6D01NTe7BBx90NTU1rr6+3r355pvua1/7mrvqqqtcS0uL9dITZuHChS4UCrmqqip35MiR6Hby5MnoPvfdd58bMWKE27p1q9u5c6crLi52xcXFhqtOvPOdh7q6Ovfkk0+6nTt3uvr6erdp0yY3atQoN2XKFOOVx+oVAXLOueeee86NGDHCDRgwwE2ePNlt377dekndbu7cuS43N9cNGDDAXX755W7u3Lmurq7OellJ99ZbbzlJZ23z5s1zzp35KPZjjz3msrOzXTAYdNOmTXO1tbW2i06Cc52HkydPuunTp7thw4a51NRUN3LkSLdgwYI+9z9pnf3zS3Jr1qyJ7vPJJ5+473znO+6yyy5zgwcPdrfccos7cuSI3aKT4Hzn4cCBA27KlCkuIyPDBYNBd+WVV7qHHnrIhcNh24V/Dr+OAQBgose/BwQA6JsIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP/D8VJCAk46E12AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5oSsHDyKdOV"
   },
   "source": [
    "## 3. Flatten the inputs into vectors\n",
    "\n",
    "When we load the data with Keras, the images are not flattened. So we flatten them into vectors to train with an MLP model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FMW07LxNKkcG"
   },
   "source": [
    "X_train = X_train.reshape(-1, 28*28)\n",
    "X_test = X_test.reshape(-1, 28*28)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CpvkubAO-pE"
   },
   "source": [
    "## 4. Convert label vectors into one-hot encodings\n",
    "\n",
    "When using Keras for classification, the labels have to be converted into one-hot encoding vectors. We can do this using the [to_categorial](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) method."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0rPJrL4xL8rh"
   },
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = 10\n",
    "Y_train = to_categorical(Y_train, num_classes)\n",
    "Y_test = to_categorical(Y_test, num_classes)\n",
    "\n",
    "print(Y_train.shape, Y_test.shape)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo4RjIAaPGxa"
   },
   "source": [
    "## 4. Define the MLP model\n",
    "\n",
    "We can define an MLP model using a [Sequential](https://keras.io/api/models/sequential/) model and the [Dense](https://keras.io/api/layers/core_layers/dense/) layers. In most cases, we will define a model as a Sequential model, and then add layers to it one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XElZvngXCsT6"
   },
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 00:59:04.342183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZONj3oJJcZZ"
   },
   "source": [
    "## 5. Compile the model\n",
    "\n",
    "Before training a Keras model, we need to compile it to set up all the options for training, such as loss function, optimizer, and evaluation metrics. Here we will use cross entropy loss and the SGD optimizer. Our evaluation metric will be accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c25OV_XaJgIT"
   },
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2XuB7yxPMiK"
   },
   "source": [
    "## 6. Train the model\n",
    "\n",
    "Now we can train the model using the `fit(...)` method. We can specify the number of epochs and batch size for training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O4d4eFVnFY8R"
   },
   "source": [
    "model.fit(X_train, Y_train, epochs=100, batch_size=128)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.3569 - accuracy: 0.6463\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.5287 - accuracy: 0.8635\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8884\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3527 - accuracy: 0.9005\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3231 - accuracy: 0.9078\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3018 - accuracy: 0.9135\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.9183\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.9228\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2578 - accuracy: 0.9266\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.9291\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2371 - accuracy: 0.9322\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2282 - accuracy: 0.9347\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2201 - accuracy: 0.9372\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.9388\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9410\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1996 - accuracy: 0.9427\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1939 - accuracy: 0.9448\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9463\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.9484\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9494\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.9509\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9518\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1652 - accuracy: 0.9533\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1612 - accuracy: 0.9545\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9555\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1540 - accuracy: 0.9564\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9572\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1474 - accuracy: 0.9580\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1443 - accuracy: 0.9593\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1414 - accuracy: 0.9599\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1385 - accuracy: 0.9604\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1358 - accuracy: 0.9614\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1331 - accuracy: 0.9623\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.9626\n",
      "Epoch 35/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9638\n",
      "Epoch 36/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1258 - accuracy: 0.9639\n",
      "Epoch 37/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1235 - accuracy: 0.9651\n",
      "Epoch 38/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1214 - accuracy: 0.9657\n",
      "Epoch 39/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1191 - accuracy: 0.9660\n",
      "Epoch 40/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1171 - accuracy: 0.9665\n",
      "Epoch 41/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9671\n",
      "Epoch 42/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1131 - accuracy: 0.9677\n",
      "Epoch 43/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1113 - accuracy: 0.9682\n",
      "Epoch 44/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1096 - accuracy: 0.9690\n",
      "Epoch 45/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1076 - accuracy: 0.9694\n",
      "Epoch 46/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9700\n",
      "Epoch 47/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1044 - accuracy: 0.9702\n",
      "Epoch 48/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1028 - accuracy: 0.9709\n",
      "Epoch 49/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9718\n",
      "Epoch 51/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9724\n",
      "Epoch 52/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9723\n",
      "Epoch 53/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9730\n",
      "Epoch 54/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9734\n",
      "Epoch 55/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9741\n",
      "Epoch 56/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9745\n",
      "Epoch 57/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9754\n",
      "Epoch 58/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9753\n",
      "Epoch 59/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9754\n",
      "Epoch 60/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9760\n",
      "Epoch 61/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9761\n",
      "Epoch 62/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.9768\n",
      "Epoch 63/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0830 - accuracy: 0.9772\n",
      "Epoch 64/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0820 - accuracy: 0.9773\n",
      "Epoch 65/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.9776\n",
      "Epoch 66/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0798 - accuracy: 0.9777\n",
      "Epoch 67/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0787 - accuracy: 0.9783\n",
      "Epoch 68/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9785\n",
      "Epoch 69/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.9790\n",
      "Epoch 70/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9787\n",
      "Epoch 71/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0750 - accuracy: 0.9790\n",
      "Epoch 72/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9796\n",
      "Epoch 73/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.9795\n",
      "Epoch 74/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.9799\n",
      "Epoch 75/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9803\n",
      "Epoch 76/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0707 - accuracy: 0.9801\n",
      "Epoch 77/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9805\n",
      "Epoch 78/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9808\n",
      "Epoch 79/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0683 - accuracy: 0.9805\n",
      "Epoch 80/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9814\n",
      "Epoch 81/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9814\n",
      "Epoch 82/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9816\n",
      "Epoch 83/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.9818\n",
      "Epoch 84/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0645 - accuracy: 0.9822\n",
      "Epoch 85/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9821\n",
      "Epoch 86/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9823\n",
      "Epoch 87/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9830\n",
      "Epoch 88/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9826\n",
      "Epoch 89/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9831\n",
      "Epoch 90/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0604 - accuracy: 0.9832\n",
      "Epoch 91/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0587 - accuracy: 0.9839\n",
      "Epoch 94/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9836\n",
      "Epoch 95/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0574 - accuracy: 0.9841\n",
      "Epoch 96/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9845\n",
      "Epoch 98/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9849\n",
      "Epoch 99/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9852\n",
      "Epoch 100/100\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x15e522c20>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIMxsvj7PPNB"
   },
   "source": [
    "## 7. Evaluate the trained model on test set\n",
    "\n",
    "Finally, we can compute the model accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K1cMOdJAG1-C"
   },
   "source": [
    "_, accuracy = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(accuracy)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0875 - accuracy: 0.9729\n",
      "0.9728999733924866\n"
     ]
    }
   ]
  }
 ]
}
